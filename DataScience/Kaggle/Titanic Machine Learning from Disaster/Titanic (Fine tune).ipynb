{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ymlai\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import math\n",
    "import seaborn as sns\n",
    "from six.moves import cPickle as pickle\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From previous result\n",
    "\n",
    "From previous result, we decide to use the following models to do submission. They are:\n",
    "1. Polynomial SVM Accuracy: 83.96%\n",
    "2. XGboost Accuracy: 83.58%\n",
    "3. RBF SVM Accuracy: 82.84%\n",
    "4. Bernoulli Naive bayes Accuracy: 82.46%\n",
    "5. Logistic Accuracy: 81.72%\n",
    "6. Random forest Accuracy: 81.34%\n",
    "7. Linear SVM Accuracy: 81.34%\n",
    "8. Neural Network Accuracy: 81.34%\n",
    "9. Extra tree Accuracy: 79.85%\n",
    "10. Guassian Naive bayes Accuracy: 60.45%\n",
    "\n",
    "In this section, we will run a grid search to find the best parameter for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743497</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.503371</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.344995</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>0.734691</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>1.747178</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>-1.087045</td>\n",
       "      <td>1.952562</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>3.595210</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-1.853992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.344995</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.490320</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.344995</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>0.383123</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>1.747178</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>-1.087045</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>3.595210</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-1.853992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743497</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.487904</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.743497</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.480009</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>3.105202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.743497</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>0.359196</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>1.747178</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>-1.087045</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>5.561190</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-1.853992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.743497</td>\n",
       "      <td>2.402037</td>\n",
       "      <td>0.710763</td>\n",
       "      <td>-0.236070</td>\n",
       "      <td>1.968447</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.344995</td>\n",
       "      <td>-0.479087</td>\n",
       "      <td>1.866526</td>\n",
       "      <td>-0.428289</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>-0.518084</td>\n",
       "      <td>0.919925</td>\n",
       "      <td>-0.512148</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.344995</td>\n",
       "      <td>0.481288</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.062139</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>-0.572351</td>\n",
       "      <td>1.930190</td>\n",
       "      <td>-1.087045</td>\n",
       "      <td>1.952562</td>\n",
       "      <td>-0.322040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>-0.130744</td>\n",
       "      <td>-0.228584</td>\n",
       "      <td>-0.278148</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.179818</td>\n",
       "      <td>-0.127688</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.539377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.743497  0.481288 -0.445000 -0.503371  0.073352 -0.572351 -0.518084   \n",
       "1 -1.344995  0.481288 -0.445000  0.734691  0.073352  1.747178 -0.518084   \n",
       "2 -1.344995 -0.479087 -0.445000 -0.490320 -0.558346 -0.572351 -0.518084   \n",
       "3 -1.344995  0.481288 -0.445000  0.383123  0.073352  1.747178 -0.518084   \n",
       "4  0.743497 -0.479087 -0.445000 -0.487904 -0.558346 -0.572351 -0.518084   \n",
       "5  0.743497 -0.479087 -0.445000 -0.480009 -0.558346 -0.572351 -0.518084   \n",
       "6  0.743497 -0.479087 -0.445000  0.359196 -0.558346  1.747178 -0.518084   \n",
       "7  0.743497  2.402037  0.710763 -0.236070  1.968447 -0.572351 -0.518084   \n",
       "8 -1.344995 -0.479087  1.866526 -0.428289  0.705051 -0.572351 -0.518084   \n",
       "9 -1.344995  0.481288 -0.445000 -0.062139  0.073352 -0.572351  1.930190   \n",
       "\n",
       "         7         8         9     ...          28        29        30  \\\n",
       "0  0.919925 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "1 -1.087045  1.952562 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "2  0.919925 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "3 -1.087045 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "4  0.919925 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "5  0.919925 -0.512148  3.105202    ...    -0.02765 -0.130744 -0.228584   \n",
       "6 -1.087045 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "7  0.919925 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "8  0.919925 -0.512148 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "9 -1.087045  1.952562 -0.322040    ...    -0.02765 -0.130744 -0.228584   \n",
       "\n",
       "         31        32        33        34        35       36        37  \n",
       "0 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "1  3.595210 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765 -1.853992  \n",
       "2 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "3  3.595210 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765 -1.853992  \n",
       "4 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "5 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "6 -0.278148 -0.190843  5.561190 -0.127688 -0.061922 -0.02765 -1.853992  \n",
       "7 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "8 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "9 -0.278148 -0.190843 -0.179818 -0.127688 -0.061922 -0.02765  0.539377  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds_file = 'train_dataset.pickle'\n",
    "train_lb_file = 'train_label.pickle'\n",
    "test_ds_file = 'test_dataset.pickle'\n",
    "\n",
    "with open(train_ds_file, 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "    \n",
    "with open(train_lb_file, 'rb') as f:\n",
    "    train_label = pickle.load(f)\n",
    "    \n",
    "with open(test_ds_file, 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "    \n",
    "def transform_ds_to_input(dataset):\n",
    "    columns = [\"Pclass\", \"Embarked_enc\", \"Salutation_enc\", \"CabinArea_enc\"]\n",
    "    ds_onehot = dataset[[\"Pclass\", \"Sex_enc\", \"SibSp\", \"Parch\", \"Fare\", \"CabinArea_enc\",\\\n",
    "                                       \"Embarked_enc\", \"Salutation_enc\", \"FamilyMember\"]]\n",
    "    ds_onehot = pandas.get_dummies(ds_onehot, sparse=True, columns=columns)\n",
    "    scaler = StandardScaler().fit(ds_onehot)\n",
    "    ds_onehot_scaled = scaler.transform(ds_onehot) \n",
    "    return ds_onehot_scaled\n",
    "\n",
    "full_dataset = pandas.concat([train_dataset, test_dataset])\n",
    "full_dataset_onehot = transform_ds_to_input(full_dataset)\n",
    "train_dataset_onehot= full_dataset_onehot[:len(train_dataset)]\n",
    "test_dataset_onehot = full_dataset_onehot[len(train_dataset):]\n",
    "\n",
    "display(pandas.DataFrame(train_dataset_onehot[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_set(test_size):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(train_dataset_onehot, train_label, test_size=test_size)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning logistic regression\n",
    "\n",
    "The model parameter to optimized are\n",
    "1. C - The regularization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.075}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "parameters = {'C':[0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5, 5, 7.5]}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, C:0.3 Accuracy: 83.58%\n",
      "Logistic regression, C:0.3 Accuracy: 82.84%\n",
      "Logistic regression, C:0.3 Accuracy: 85.45%\n",
      "Logistic regression, C:0.3 Accuracy: 81.72%\n",
      "Logistic regression, C:0.3 Accuracy: 82.84%\n",
      "Logistic regression, C:0.3 Accuracy: 80.60%\n",
      "Logistic regression, C:0.3 Accuracy: 81.34%\n",
      "Logistic regression, C:0.3 Accuracy: 83.96%\n",
      "Logistic regression, C:0.3 Accuracy: 83.96%\n",
      "Logistic regression, C:0.3 Accuracy: 82.46%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = LogisticRegression(C = 0.075)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Logistic regression, C:0.3\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning RBF SVM\n",
    "\n",
    "The model parameter to optimized are\n",
    "\n",
    "1. C - regularization term\n",
    "2. Gamma - the influence of a single training example reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.75, 'gamma': 0.05}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "parameters = {'C':[0.001, 0.0025, 0.005, 0.0075, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1, 2.5, 5, 7.5], \n",
    "              'gamma':[0.00001, 0.000025, 0.00005, 0.000075, 0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, \\\n",
    "                   0.005, 0.0075, 0.01, 0.025, 0.05, 0.075]}\n",
    "rbf = SVC()\n",
    "clf = GridSearchCV(rbf, parameters, n_jobs=8)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 84.33%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 83.21%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 82.46%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 81.34%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 81.34%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 83.21%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 80.22%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 84.33%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 83.21%\n",
      "Multinominal Naive bayes regression, alpha:0.001 Accuracy: 81.34%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = SVC(gamma=0.05, C=0.75)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Multinominal Naive bayes regression, alpha:0.001\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning XGBoost\n",
    "\n",
    "The model will use tree instead of linear\n",
    "\n",
    "The parameter to be tuned are:\n",
    "1. learning_rate\n",
    "2. max_depth\n",
    "3. min_child_weight\n",
    "4. gamma\n",
    "5. subsample\n",
    "6. colsample_bytree\n",
    "7. objective\n",
    "8. learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'reg_alpha': 0.01, 'gamma': 0.2, 'subsample': 0.9, 'colsample_bytree': 0.8, 'learning_rate': 0.1, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'min_child_weight':range(2,6,1),\n",
    "    'max_depth':range(3,7,1),\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'learning_rate':[0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "clf = RandomizedSearchCV(xgb, parameters, n_jobs=8, n_iter=5000)\n",
    "clf.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 79.48%\n",
      "XGBoost Accuracy: 82.09%\n",
      "XGBoost Accuracy: 82.84%\n",
      "XGBoost Accuracy: 81.72%\n",
      "XGBoost Accuracy: 83.21%\n",
      "XGBoost Accuracy: 80.97%\n",
      "XGBoost Accuracy: 82.09%\n",
      "XGBoost Accuracy: 85.07%\n",
      "XGBoost Accuracy: 75.75%\n",
      "XGBoost Accuracy: 82.46%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = XGBClassifier(learning_rate=0.1, subsample=0.9, colsample_bytree=0.8, gamma=0.2,\n",
    "                       max_depth=5, reg_alpha=0.01, min_child_weight=3, objective= 'binary:logistic')\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"XGBoost\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Random Forest\n",
    "\n",
    "The parameter to be tuned are:\n",
    "1. max_depth\n",
    "2. max_features\n",
    "3. min_samples_split\n",
    "4. min_samples_leaf\n",
    "5. bootstrap\n",
    "6. criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'criterion': 'gini', 'min_samples_split': 9, 'max_features': 9, 'n_estimators': 16, 'min_samples_leaf': 4, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist = {\"n_estimators\" : sp_randint(3, 20),\n",
    "              \"max_depth\": [1, 2, 3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 5000\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, n_jobs=8)\n",
    "random_search.fit(train_dataset_onehot, train_label)\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Accuracy: 82.46%\n",
      "Random forest Accuracy: 80.60%\n",
      "Random forest Accuracy: 83.21%\n",
      "Random forest Accuracy: 85.45%\n",
      "Random forest Accuracy: 82.09%\n",
      "Random forest Accuracy: 82.09%\n",
      "Random forest Accuracy: 82.46%\n",
      "Random forest Accuracy: 83.21%\n",
      "Random forest Accuracy: 82.46%\n",
      "Random forest Accuracy: 79.85%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = get_train_test_set(0.3)\n",
    "    lr = RandomForestClassifier(max_features=9, bootstrap=True, min_samples_split=9, n_estimators=16, criterion='gini',\n",
    "                       min_samples_leaf=4, max_depth=None)  \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"%s Accuracy: %.2f%%\" % (\"Random forest\", accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission, select the best model for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.77990, better than gender classifier 0.76555\n",
    "\n",
    "clf1 = RandomForestClassifier(max_features=9, bootstrap=True, min_samples_split=9, n_estimators=16, criterion='gini',\n",
    "                       min_samples_leaf=4, max_depth=None)  \n",
    "clf1.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf1.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_rf.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.78469, better than gender classifier 0.76555\n",
    "\n",
    "clf2 = XGBClassifier(learning_rate=0.1, subsample=0.9, colsample_bytree=0.8, gamma=0.2,\n",
    "                       max_depth=5, reg_alpha=0.01, min_child_weight=3, objective= 'binary:logistic')\n",
    "clf2.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf2.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_xg.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission score is 0.78469, better than gender classifier 0.76555\n",
    "\n",
    "clf3 = SVC(gamma=0.05, C=0.75)\n",
    "clf3.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf3.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_svc.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.77512, better than gender classifier 0.76555\n",
    "\n",
    "clf4 = LogisticRegression(C = 0.075)\n",
    "clf4.fit(train_dataset_onehot, train_label)\n",
    "r_pred = clf4.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_lr.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Submission score is 0.81818, better than gender classifier 0.76555\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('rf', clf1), ('xgb', clf2), ('svm', clf3), ('lr', clf4)], voting='hard')\n",
    "eclf2.fit(train_dataset_onehot, train_label) \n",
    "r_pred = eclf2.predict(test_dataset_onehot)\n",
    "r_predictions = [int(round(value)) for value in r_pred]\n",
    "\n",
    "submission_df = pandas.DataFrame(index=test_dataset.index, columns=[\"Survived\"])\n",
    "submission_df[\"Survived\"] = r_predictions\n",
    "submission_df.to_csv(\"submission_best_voting.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
